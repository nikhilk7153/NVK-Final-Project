{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVxjwqpPOYoF"
      },
      "outputs": [],
      "source": [
        "!apt update\n",
        "!apt install enchant --fix-missing\n",
        "!apt install -qq enchant\n",
        "!pip install pyenchant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NqHmig2RV2s"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import csv\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import sys\n",
        "from nltk.corpus import wordnet\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import torch #pytorch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import enchant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXJCEMIUwHLx"
      },
      "outputs": [],
      "source": [
        "!pip install -U torchdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext"
      ],
      "metadata": {
        "id": "PyEf3bbKciPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_Cdcf7D12Q3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "import enchant\n",
        "\n",
        "class YelpData(torch.utils.data.Dataset):\n",
        "  def __init__(self, dataset):\n",
        "    self.dataset = dataset\n",
        "    self.word_to_idx = {\"<PAD>\":0, \"<UNK>\": 1, \"<END>\": 2}\n",
        "    self.indexes = []\n",
        "    self.labels = []\n",
        "    self.sen_to_idxs()\n",
        "\n",
        "\n",
        "  def sen_to_idxs(self):\n",
        "\n",
        "    d = enchant.Dict(\"en_US\") \n",
        "    count = 3\n",
        "    for i in range(len(self.dataset)):\n",
        "      words = self.dataset[i][1].split(\" \")\n",
        "\n",
        "      for word in words:\n",
        "        word = word.lower()\n",
        "        if word and d.check(word):\n",
        "          if word not in self.word_to_idx:\n",
        "            self.word_to_idx[word] = count\n",
        "            count += 1\n",
        "\n",
        "    self.filtered_dict = {}\n",
        "    for key, value in self.word_to_idx.items():\n",
        "      if value >= 5:\n",
        "        self.filtered_dict[key] = value\n",
        "\n",
        "    self.word_to_idx = self.filtered_dict\n",
        "        \n",
        "    for i in range(len(self.dataset)):\n",
        "      if self.dataset[i][0] == 2:\n",
        "        self.labels.append(1)\n",
        "      else:\n",
        "        self.labels.append(0)\n",
        "      sen = []\n",
        "      words = self.dataset[i][1].split(\" \")\n",
        "      for word in words:\n",
        "        word = word.lower()\n",
        "        if word:\n",
        "          if word in self.word_to_idx:\n",
        "            sen.append(self.word_to_idx[word])\n",
        "          else:\n",
        "            sen.append(1)\n",
        "\n",
        "      sen.append(2)\n",
        "      sen = sen[:200]\n",
        "      self.indexes.append(sen)\n",
        " \n",
        "    for i in range(len(self.indexes)):\n",
        "      while len(self.indexes[i]) < 200:\n",
        "          self.indexes[i].append(0)\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.indexes)\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    return torch.LongTensor(self.indexes[idx]).squeeze(), torch.LongTensor([self.labels[idx]]).squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaeoi28Em2rQ"
      },
      "outputs": [],
      "source": [
        "import torchdata\n",
        "import torchtext\n",
        "\n",
        "\n",
        "data = torchtext.datasets.YelpReviewPolarity(root='.data', split='train')\n",
        "data = list(data)\n",
        "data = [(x[0], x[1]) for x in data]\n",
        "train_data, test_data = data[:30000], data[30000:36000]\n",
        "\n",
        "train_data_tensor = YelpData(train_data)\n",
        "test_data_tensor = YelpData(test_data)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data_tensor, batch_size=32, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data_tensor, batch_size=32, shuffle=True, num_workers=2, drop_last=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A66U93xinZ2A"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedded_layer = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0)\n",
        "        self.lstm_layer = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.linear = nn.Linear(hidden_dim, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        embed_x = self.embedded_layer(x)\n",
        "        lstm_x = self.lstm_layer(embed_x)[0]\n",
        "        final_output = self.linear(lstm_x[:,-1])\n",
        "        return final_output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clDOCf6Hy0Gu"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LSTM(128, 128, len(train_data_tensor.word_to_idx), 2).to(device)\n",
        "loss_function = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for _ in range(10):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(inputs)\n",
        "    \n",
        "        loss = loss_function(predictions, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"drive/My Drive/lstm.pt\")"
      ],
      "metadata": {
        "id": "HKGjc5A86yQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}